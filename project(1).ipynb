{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project : Text To AI Image Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Image Generator with Stable Diffusion**\n",
    "\n",
    "This is a simple and powerful AI image generation web app built using Hugging Face's diffusers library and deployed on Gradio + Hugging Face Spaces.\n",
    "\n",
    "It uses **Stable Diffusion v1.5** to generate high-quality images from text prompts given by the user.\n",
    "\n",
    "---\n",
    "\n",
    " **Features**\n",
    "- Text-to-Image generation using Stable Diffusion\n",
    "- Clean and simple web interface via Gradio\n",
    "- Fast image generation with GPU support (CUDA)\n",
    "- Fully deployable and shareable via Hugging Face Spaces\n",
    "\n",
    "---\n",
    "\n",
    "**Demo**\n",
    "Try it here: https://<your-space-name>.huggingface.space\n",
    "(Replace with your actual Hugging Face Space URL)\n",
    "\n",
    "**How It Works**\n",
    "1. User enters a text prompt (e.g., \"a cat sitting on the moon\").\n",
    "2. The backend runs Stable Diffusion to convert text into an image.\n",
    "3. The output image is displayed on the web interface in seconds.\n",
    "\n",
    "**Requirements**\n",
    "These packages are required (also saved in requirements.txt):\n",
    "1. diffusers\n",
    "2. transformers\n",
    "3. accelerate\n",
    "4. safetensors\n",
    "5. torch\n",
    "6. gradio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 1:** Install and upgrade key HuggingFace libraries\n",
    "\n",
    "1. diffusers\n",
    "2. transformers\n",
    "3. accelerate\n",
    "4. safetensors"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install diffusers==0.25.0 transformers accelerate gradio --quiet\n",
    "!pip install diffusers transformers accelerate --upgrade\n",
    "!pip install safetensors"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 2:** Load the Pretrained Model\n",
    "\n",
    "* Use StableDiffusionPipeline from diffusers:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import matplotlib.pyplot as plt"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 3:** Login to Hugging Face\n",
    "* Use a token to authenticate access to models. **Never share your token publicly!**\n",
    "* You can use `from huggingface_hub import login` and then `login()` with your token."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from huggingface_hub import login\n",
    "# login('YOUR_HF_TOKEN')  # Replace with your token, but never share this in public code"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 4:** Generate Image from Prompt\n",
    "* User inputs a text prompt, and the model generates an image"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16,\n",
    "    use_safetensors=True\n",
    ")\n",
    "pipe = pipe.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 5:** Deploying an Interactive Web Interface Using Gradio\n",
    "Use Gradio to create an interactive web-based interface for the text-to-image generation model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import gradio as gr\n",
    "\n",
    "def generate_image(prompt):\n",
    "    image = pipe(prompt).images[0]\n",
    "    return image"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 6:** Building the Web Interface"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "gr.Interface(\n",
    "    fn=generate_image,\n",
    "    inputs=gr.Textbox(\n",
    "        label=\"üìù Enter your image prompt\",\n",
    "        placeholder=\"e.g. A surreal landscape with floating islands\"\n",
    "    ),\n",
    "    outputs=gr.Image(type=\"pil\", label=\"üñºÔ∏è Generated Image\"),\n",
    "    title=\"üé® Text-to-Image Generator (Stable Diffusion)\",\n",
    "    description=\"Enter a creative prompt to generate AI images using Stable Diffusion!\",\n",
    "    theme=\"default\"\n",
    ").launch(share=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Possible Challenges Faced**\n",
    "- Environment/Dependency Issues\n",
    "- Hugging Face Authentication Problems\n",
    "- Model Loading Errors\n",
    "- Image Generation Failures\n",
    "- Debugging and Exception Handling\n",
    "- Gradio Deployment Challenges\n",
    "- Hardware Limitations (Colab)\n",
    "- Performance and Usability Gaps\n",
    "- Security and Safety Concerns\n",
    "- Missing Functional Enhancements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
